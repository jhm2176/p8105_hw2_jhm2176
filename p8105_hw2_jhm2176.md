Homework 2
================
Jenesis Merriman
October 5, 2022

``` r
library(tidyverse)
library(readxl)
```

### Problem 1

The below code uses `readr` and `janitor::clean_names` to import and
clean the data. It also uses `select` to retain the variables *line,
station, name, station latitude / longitude, routes served, entry,
vending, entrance type*, and *ADA compliance* and `mutate` to convert
the *entry* variable type from character to a logical variable.

``` r
transit_data = 
  read_csv(
    "./data/NYC_Transit_Subway_Entrance_And_Exit_Data.csv",
    col_types = cols(Route8 = "c", Route9 = "c", Route10 = "c", Route11 = "c")) %>%
  janitor::clean_names() %>%
  select(line, station_name, station_latitude,station_longitude, route1:route11, entry,
         exit_only, vending,entrance_type, ada) %>%
  mutate(entry = recode(entry, "YES" = TRUE, "NO" = FALSE))
```

This dataset focuses on NYC transit data and includes the variables
*line, station name, station latitude, station longitude, routes served,
entry, vending, entrance type*, and *ADA compliance*. In order to clean
the data, I imported the data, updated variable types, cleaned variable
names, and selected the relevant columns. I then updated *entry* from
`yes` / `no` to a logical variable. The resulting data set is 1868 rows
x 20 columns. These data are not “tidy” in its current state. To further
tidy our data, we would need to convert *route* variables from wide to
long format.

I will now use R to answer the following questions.

**How many distinct stations are there?**

``` r
transit_data %>% 
  select(station_name, line) %>% 
  distinct
## # A tibble: 465 × 2
##    station_name             line    
##    <chr>                    <chr>   
##  1 25th St                  4 Avenue
##  2 36th St                  4 Avenue
##  3 45th St                  4 Avenue
##  4 53rd St                  4 Avenue
##  5 59th St                  4 Avenue
##  6 77th St                  4 Avenue
##  7 86th St                  4 Avenue
##  8 95th St                  4 Avenue
##  9 9th St                   4 Avenue
## 10 Atlantic Av-Barclays Ctr 4 Avenue
## # … with 455 more rows
```

**Answer:** There are 465 distinct stations in the NYC transit system,
according to our dataset.

**How many stations are ADA compliant?**

``` r
transit_data %>% 
  filter(ada == TRUE) %>% 
  select(station_name, line) %>% 
  distinct
## # A tibble: 84 × 2
##    station_name                   line           
##    <chr>                          <chr>          
##  1 Atlantic Av-Barclays Ctr       4 Avenue       
##  2 DeKalb Av                      4 Avenue       
##  3 Pacific St                     4 Avenue       
##  4 Grand Central                  42nd St Shuttle
##  5 34th St                        6 Avenue       
##  6 47-50th Sts Rockefeller Center 6 Avenue       
##  7 Church Av                      6 Avenue       
##  8 21st St                        63rd Street    
##  9 Lexington Av                   63rd Street    
## 10 Roosevelt Island               63rd Street    
## # … with 74 more rows
```

**Answer:** There are 84 ADA compliant stations in the NYC transit
system, according to our dataset.

**What proportion of station entrances / exits without vending allow
entrance?**

``` r
transit_data %>% 
  filter(vending == "NO") %>% 
  pull(entry) %>% 
  mean
## [1] 0.3770492
```

**Answer:** The proportion of station entrances / exits without vending
that allow entrance is 0.377.

**How many distinct stations serve the A train? Of the stations that
serve the A train, how many are ADA compliant?** To answer these
questions, I will first reformat the data so that route number and route
name are distinct variables, then `filter()` by route name and ADA
compliance:

``` r
transit_data %>%
  pivot_longer(
    route1:route11,
    names_to = "route_number", 
    names_prefix = "route",
    values_to = "route_name") %>%
    filter(route_name == "A") %>%
  select(station_name, line) %>% 
  distinct
## # A tibble: 60 × 2
##    station_name                  line           
##    <chr>                         <chr>          
##  1 Times Square                  42nd St Shuttle
##  2 125th St                      8 Avenue       
##  3 145th St                      8 Avenue       
##  4 14th St                       8 Avenue       
##  5 168th St - Washington Heights 8 Avenue       
##  6 175th St                      8 Avenue       
##  7 181st St                      8 Avenue       
##  8 190th St                      8 Avenue       
##  9 34th St                       8 Avenue       
## 10 42nd St                       8 Avenue       
## # … with 50 more rows

transit_data %>%
  pivot_longer(
    route1:route11,
    names_to = "route_number", 
    names_prefix = "route",
    values_to = "route_name") %>%
  filter(route_name == "A", ada == TRUE) %>% 
  select(station_name, line) %>% 
  distinct
## # A tibble: 17 × 2
##    station_name                  line            
##    <chr>                         <chr>           
##  1 14th St                       8 Avenue        
##  2 168th St - Washington Heights 8 Avenue        
##  3 175th St                      8 Avenue        
##  4 34th St                       8 Avenue        
##  5 42nd St                       8 Avenue        
##  6 59th St                       8 Avenue        
##  7 Inwood - 207th St             8 Avenue        
##  8 West 4th St                   8 Avenue        
##  9 World Trade Center            8 Avenue        
## 10 Times Square-42nd St          Broadway        
## 11 59th St-Columbus Circle       Broadway-7th Ave
## 12 Times Square                  Broadway-7th Ave
## 13 8th Av                        Canarsie        
## 14 Franklin Av                   Franklin        
## 15 Euclid Av                     Fulton          
## 16 Franklin Av                   Fulton          
## 17 Howard Beach                  Rockaway
```

**Answer:** 60 distinct stations serve the A train. Of these stations,
17 are ADA compliant.

### Problem 2

First, I will read and clean the Mr. Trash Wheel sheet, adding the
variable *class* to keep track of data for future combining:

``` r
mr_trash = 
  read_excel(
    "data/NEW Trash Wheel Collection Data.xlsx", sheet = "Mr. Trash Wheel", 
    range = "A2:N549") %>%
  janitor::clean_names() %>%
  drop_na(dumpster) %>%
  mutate(
    sports_balls = as.integer(sports_balls),
    year = as.double(year), 
    class = "mister")
```

Next, using similar methods as above, I will import, clean, and organize
the data for Professor Trash Wheel, adding the variable *class* to keep
track of data for future combining:

``` r
prof_trash =
  read_excel(
    "data/NEW Trash Wheel Collection Data.xlsx", 
    sheet = "Professor Trash Wheel", range = "A2:M96") %>% 
  janitor::clean_names() %>%
  drop_na(dumpster) %>%
  mutate(class = "professor")
```

Finally, I will combine the Professor Trash Wheel data with the
Mr. Trash Wheel data to produce a single tidy dataset. I will use
`full_join` because observations in each dataset are distinct, according
to their website.

``` r
trash_tidy = full_join(mr_trash, prof_trash)
trash_tidy
## # A tibble: 641 × 15
##    dumpster month  year date                weight_tons volume…¹ plast…² polys…³
##       <dbl> <chr> <dbl> <dttm>                    <dbl>    <dbl>   <dbl>   <dbl>
##  1        1 May    2014 2014-05-16 00:00:00        4.31       18    1450    1820
##  2        2 May    2014 2014-05-16 00:00:00        2.74       13    1120    1030
##  3        3 May    2014 2014-05-16 00:00:00        3.45       15    2450    3100
##  4        4 May    2014 2014-05-17 00:00:00        3.1        15    2380    2730
##  5        5 May    2014 2014-05-17 00:00:00        4.06       18     980     870
##  6        6 May    2014 2014-05-20 00:00:00        2.71       13    1430    2140
##  7        7 May    2014 2014-05-21 00:00:00        1.91        8     910    1090
##  8        8 May    2014 2014-05-28 00:00:00        3.7        16    3580    4310
##  9        9 June   2014 2014-06-05 00:00:00        2.52       14    2400    2790
## 10       10 June   2014 2014-06-11 00:00:00        3.76       18    1340    1730
## # … with 631 more rows, 7 more variables: cigarette_butts <dbl>,
## #   glass_bottles <dbl>, grocery_bags <dbl>, chip_bags <dbl>,
## #   sports_balls <int>, homes_powered <dbl>, class <chr>, and abbreviated
## #   variable names ¹​volume_cubic_yards, ²​plastic_bottles, ³​polystyrene
```

**Description:** The trash_tidy dataset displays data for dumpsters
filled by Mr. Trash Wheel and Professor Trash Wheel. The resulting
dataset contains 641 observations of 15 variables, including the new
variable *class* to distinguish dumpster type. Key variables include
*date, weight, volume*, trash type *(plastic bottles:sports balls)*, and
*homes powered* by the trash once incinerated. According to our data,
the total weight of trash collected by Professor Trash Wheel is 190.12
tons. The total number of sports balls collected by Mr. Trash wheel in
2020 is 856.

### Problem 3

First, I will clean the data in pols-month.csv and save it as **pols**.
This code will use `separate` to break up the variable *mon* into
integer variables year, month, and day; `mutate` to replace month number
with month name; `pivot_longer` to create a *president* variable taking
values gop and dem, and `select` to remove *prez_dem*, *prez_gop*, and
*day*.

``` r
pols = read_csv("data/fivethirtyeight_datasets/pols-month.csv") %>%
  janitor::clean_names() %>%
  separate(col = mon, into = c("year", "month", "day"), sep = "-") %>%
  select(-day, -prez_dem) %>%
  mutate(
    month = month.name[as.numeric(month)], 
    month = factor(month, levels = month.name),
    year = as.numeric(year),
    prez_gop = recode(prez_gop, `1` = "gop", `0` = "dem", `2` = "temp")) %>%
  pivot_longer(
    cols = prez_gop,
    names_to = NULL,
    values_to = "president")
```

**Note:** Original presidential data from August 1974 to December 1974
is coded as 2 instead of 0 or 1, likely due to Gerald Ford’s temporary
presidency in light of Richard Nixon’s resignation during this time. For
this reason, I recoded *prez_gop* values of 2 as “temp”, 1 as “gop”, 0
as “dem”, and piped these into my `piivot_longer` function.

Second, I will clean the data is snp.csv using a similar process as
above. I will save this data as **snp**. For consistency across
datasets, I will arrange according to year and month and organize so
that year and month are the leading columns.

``` r
snp = read_csv("data/fivethirtyeight_datasets/snp.csv") %>%
  janitor::clean_names() %>%
  separate(col = date, into = c("month", "day", "year"), sep = "/") %>%
  mutate(
    month = month.name[as.numeric(month)],
    month = factor(month, levels = month.name), 
    year = ifelse(as.numeric(year) > 22, as.numeric(year) + 1900,
                  as.numeric(year) + 2000)) %>%
  arrange(year, month) %>%
  select(year, month, close)
```

Third, I will tidy the data in unemployment.csv so that it can be merged
with the previous datasets. I will save this data as **unemployment**.
This process will involve switching from “wide” to “long” format with
`pivot_longer`; ensuring that key variables have the same name with
`rename`; and ensuring that key variables take the same values with
`mutate`.

``` r
unemployment = read_csv("data/fivethirtyeight_datasets/unemployment.csv") %>%
  janitor::clean_names() %>%
  rename(
    January = jan,
    February = feb,
    March = mar,
    April = apr,
    May = may,
    June = jun,
    July = jul,
    August = aug,
    September = sep,
    October = oct,
    November = nov,
    December = dec) %>%
  pivot_longer(
    January:December,
    names_to = "month", 
    values_to = "unemployment_percentage") %>%
  mutate(month = factor(month, levels = month.name))
```

Finally, I will join the datasets with `left_join` by merging the
**snp** dataset into **pols** and merging **unemployment_tidy** into the
result.

``` r
pols_snp_merge = left_join(pols, snp)
```

``` r
final_merge = left_join(pols_snp_merge, unemployment)
final_merge
## # A tibble: 822 × 11
##     year month     gov_gop sen_gop rep_gop gov_dem sen_dem rep_dem presi…¹ close
##    <dbl> <fct>       <dbl>   <dbl>   <dbl>   <dbl>   <dbl>   <dbl> <chr>   <dbl>
##  1  1947 January        23      51     253      23      45     198 dem        NA
##  2  1947 February       23      51     253      23      45     198 dem        NA
##  3  1947 March          23      51     253      23      45     198 dem        NA
##  4  1947 April          23      51     253      23      45     198 dem        NA
##  5  1947 May            23      51     253      23      45     198 dem        NA
##  6  1947 June           23      51     253      23      45     198 dem        NA
##  7  1947 July           23      51     253      23      45     198 dem        NA
##  8  1947 August         23      51     253      23      45     198 dem        NA
##  9  1947 September      23      51     253      23      45     198 dem        NA
## 10  1947 October        23      51     253      23      45     198 dem        NA
## # … with 812 more rows, 1 more variable: unemployment_percentage <dbl>, and
## #   abbreviated variable name ¹​president
```

**Description:** This homework includes three FiveThirtyEight datasets:
pols-month.csv as **pols**, snp.csv as **snp**, and unemployment.csv as
**unemployment**. The updated **pols** data contains 822 observations of
9 variables related to the number of national politicians who are
democratic or republican at any given time. The updated **snp** data
includes 787 observations of 3 variables related to Standard & Poor’s
stock market index (S&P). The variable close represents the closing
values of the S&P stock index on the associated date. The updated
**unemployment** data includes 816 observations of 3 variables,
displaying the percentage of unemployment for each month in each
associated year. The resulting data set “final_merge” merges data from
all three datasets using two `left_joins`. This final dataset contains
822 observations of 11 variables. Key variables include *year*, *month*,
*president*, *close*, and *unemployment_percentage*.
