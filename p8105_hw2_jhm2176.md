Homework 2
================
Jenesis Merriman
October 5, 2022

``` r
library(tidyverse)
```

    ## ── Attaching packages ─────────────────────────────────────── tidyverse 1.3.2 ──
    ## ✔ ggplot2 3.3.6      ✔ purrr   0.3.4 
    ## ✔ tibble  3.1.8      ✔ dplyr   1.0.10
    ## ✔ tidyr   1.2.0      ✔ stringr 1.4.1 
    ## ✔ readr   2.1.2      ✔ forcats 0.5.2 
    ## ── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──
    ## ✖ dplyr::filter() masks stats::filter()
    ## ✖ dplyr::lag()    masks stats::lag()

``` r
library(readxl)
```

## Problem 1

The below code uses `readr` and `janitor::clean_names()` to import and
clean the data. It also uses `select` to retain line, station, name,
station latitude / longitude, routes served, entry, vending, entrance
type, and ADA compliance and and `mutate` to convert the entry variable
from character to a logical variable.

``` r
transit_data = read_csv(
  file = "./data/NYC_Transit_Subway_Entrance_And_Exit_Data.csv",
  col_types = cols(Route8 = "c", Route9 = "c", Route10 = "c", Route11 = "c")) %>%
  janitor::clean_names() %>%
  select(line, station_name, station_latitude,
         station_longitude, route1:route11, entry, vending,
         entrance_type, ada)  %>%
  mutate(entry = recode(entry, "YES" = TRUE, "NO" = FALSE))
```

This dataset focuses on NYC transit data and includes the variables
line, station, name, station latitude, station longitude, routes served,
entry, vending, entrance type, and ADA compliance. In order to clean the
data, I imported the data, updated variable types, cleaned variable
names, and selected the relevant columns. I then updated `entry` from
`yes` / `no` to a logical variable. The resulting data set is 1868 rows
x 19 columns. These data are not “tidy” in its current state. To further
tidy our data, we would need to convert `route` variables from wide to
long format.

**How many distinct stations are there?**

``` r
transit_data %>% 
  select(station_name, line) %>% 
  distinct
```

    ## # A tibble: 465 × 2
    ##    station_name             line    
    ##    <chr>                    <chr>   
    ##  1 25th St                  4 Avenue
    ##  2 36th St                  4 Avenue
    ##  3 45th St                  4 Avenue
    ##  4 53rd St                  4 Avenue
    ##  5 59th St                  4 Avenue
    ##  6 77th St                  4 Avenue
    ##  7 86th St                  4 Avenue
    ##  8 95th St                  4 Avenue
    ##  9 9th St                   4 Avenue
    ## 10 Atlantic Av-Barclays Ctr 4 Avenue
    ## # … with 455 more rows

*There are 465 distinct stations in the NYC transit system, according to
our dataset.*

**How many stations are ADA compliant?**

``` r
transit_data %>% 
  filter(ada == TRUE) %>% 
  select(station_name, line) %>% 
  distinct
```

    ## # A tibble: 84 × 2
    ##    station_name                   line           
    ##    <chr>                          <chr>          
    ##  1 Atlantic Av-Barclays Ctr       4 Avenue       
    ##  2 DeKalb Av                      4 Avenue       
    ##  3 Pacific St                     4 Avenue       
    ##  4 Grand Central                  42nd St Shuttle
    ##  5 34th St                        6 Avenue       
    ##  6 47-50th Sts Rockefeller Center 6 Avenue       
    ##  7 Church Av                      6 Avenue       
    ##  8 21st St                        63rd Street    
    ##  9 Lexington Av                   63rd Street    
    ## 10 Roosevelt Island               63rd Street    
    ## # … with 74 more rows

*There are 84 ADA compliant stations in the NYC transit system,
according to our dataset.*

**What proportion of station entrances / exits without vending allow
entrance?**

``` r
transit_data %>% 
  filter(vending == "NO") %>% 
  pull(entry) %>% 
  mean
```

    ## [1] 0.3770492

*The proportion of station entrances / exits without vending that allow
entrance is 0.377.*

**How many distinct stations serve the A train? Of the stations that
serve the A train, how many are ADA compliant?** To answer these
questions, I will first reformat the data so that route number and route
name are distinct variables:

``` r
transit_data %>%
  pivot_longer(
    route1:route11,
    names_to = "route_number", 
    names_prefix = "route",
    values_to = "route_name") %>%
    filter(route_name == "A") %>%
  select(station_name, line) %>% 
  distinct
```

    ## # A tibble: 60 × 2
    ##    station_name                  line           
    ##    <chr>                         <chr>          
    ##  1 Times Square                  42nd St Shuttle
    ##  2 125th St                      8 Avenue       
    ##  3 145th St                      8 Avenue       
    ##  4 14th St                       8 Avenue       
    ##  5 168th St - Washington Heights 8 Avenue       
    ##  6 175th St                      8 Avenue       
    ##  7 181st St                      8 Avenue       
    ##  8 190th St                      8 Avenue       
    ##  9 34th St                       8 Avenue       
    ## 10 42nd St                       8 Avenue       
    ## # … with 50 more rows

``` r
transit_data %>%
  pivot_longer(
    route1:route11,
    names_to = "route_number", 
    names_prefix = "route",
    values_to = "route_name") %>%
  filter(route_name == "A", ada == TRUE) %>% 
  select(station_name, line) %>% 
  distinct
```

    ## # A tibble: 17 × 2
    ##    station_name                  line            
    ##    <chr>                         <chr>           
    ##  1 14th St                       8 Avenue        
    ##  2 168th St - Washington Heights 8 Avenue        
    ##  3 175th St                      8 Avenue        
    ##  4 34th St                       8 Avenue        
    ##  5 42nd St                       8 Avenue        
    ##  6 59th St                       8 Avenue        
    ##  7 Inwood - 207th St             8 Avenue        
    ##  8 West 4th St                   8 Avenue        
    ##  9 World Trade Center            8 Avenue        
    ## 10 Times Square-42nd St          Broadway        
    ## 11 59th St-Columbus Circle       Broadway-7th Ave
    ## 12 Times Square                  Broadway-7th Ave
    ## 13 8th Av                        Canarsie        
    ## 14 Franklin Av                   Franklin        
    ## 15 Euclid Av                     Fulton          
    ## 16 Franklin Av                   Fulton          
    ## 17 Howard Beach                  Rockaway

*60 distinct stations serve the A train. Of these stations, 17 are ADA
compliant.*

## Problem 2

First, I will read and clean the Mr. Trash Wheel sheet, adding the
variable ‘sheet’ to keep track of data for future combining:

``` r
mr_trash = read_excel(
  "data/NEW Trash Wheel Collection Data.xlsx", sheet = "Mr. Trash Wheel", range = 
    "A2:N535") %>% 
  janitor::clean_names() %>%
  mutate(sports_balls = as.integer(sports_balls), dumpster = as.double(dumpster), year = as.double(year), class =
           "mister") %>%
  drop_na()

print(mr_trash)
```

    ## # A tibble: 486 × 15
    ##    dumpster month  year date                weight_tons volume…¹ plast…² polys…³
    ##       <dbl> <chr> <dbl> <dttm>                    <dbl>    <dbl>   <dbl>   <dbl>
    ##  1        1 May    2014 2014-05-16 00:00:00        4.31       18    1450    1820
    ##  2        2 May    2014 2014-05-16 00:00:00        2.74       13    1120    1030
    ##  3        3 May    2014 2014-05-16 00:00:00        3.45       15    2450    3100
    ##  4        4 May    2014 2014-05-17 00:00:00        3.1        15    2380    2730
    ##  5        5 May    2014 2014-05-17 00:00:00        4.06       18     980     870
    ##  6        6 May    2014 2014-05-20 00:00:00        2.71       13    1430    2140
    ##  7        7 May    2014 2014-05-21 00:00:00        1.91        8     910    1090
    ##  8        8 May    2014 2014-05-28 00:00:00        3.7        16    3580    4310
    ##  9        9 June   2014 2014-06-05 00:00:00        2.52       14    2400    2790
    ## 10       10 June   2014 2014-06-11 00:00:00        3.76       18    1340    1730
    ## # … with 476 more rows, 7 more variables: cigarette_butts <dbl>,
    ## #   glass_bottles <dbl>, grocery_bags <dbl>, chip_bags <dbl>,
    ## #   sports_balls <int>, homes_powered <dbl>, class <chr>, and abbreviated
    ## #   variable names ¹​volume_cubic_yards, ²​plastic_bottles, ³​polystyrene

Next, using similiar methods as above, I will import, clean, and
organize the data for Professor Trash Wheel, adding the variable ‘sheet’
to keep track of data for future combining:

``` r
prof_trash = read_excel("data/NEW Trash Wheel Collection Data.xlsx", 
    sheet = "Professor Trash Wheel", range = "A2:M96") %>% 
  janitor::clean_names() %>%
  mutate(class = "professor") %>%
  drop_na()

print(prof_trash)
```

    ## # A tibble: 82 × 14
    ##    dumpster month     year date                weight_…¹ volum…² plast…³ polys…⁴
    ##       <dbl> <chr>    <dbl> <dttm>                  <dbl>   <dbl>   <dbl>   <dbl>
    ##  1        1 January   2017 2017-01-02 00:00:00      1.79      15    1950    6080
    ##  2        2 January   2017 2017-01-30 00:00:00      1.58      15    9540   11230
    ##  3        3 February  2017 2017-02-26 00:00:00      2.32      18    8350    9210
    ##  4        4 February  2017 2017-02-26 00:00:00      3.72      15    8590    1030
    ##  5        5 February  2017 2017-02-28 00:00:00      1.45      15    7830    9950
    ##  6        6 March     2017 2017-03-30 00:00:00      1.71      15    8210   10340
    ##  7        7 April     2017 2017-04-01 00:00:00      1.82      15    9830   11020
    ##  8        8 April     2017 2017-04-20 00:00:00      2.37      15    9240    8760
    ##  9        9 May       2017 2017-05-10 00:00:00      2.64      15    9540    8810
    ## 10       10 May       2017 2017-05-26 00:00:00      2.78      15    8230    7800
    ## # … with 72 more rows, 6 more variables: cigarette_butts <dbl>,
    ## #   glass_bottles <dbl>, grocery_bags <dbl>, chip_bags <dbl>,
    ## #   homes_powered <dbl>, class <chr>, and abbreviated variable names
    ## #   ¹​weight_tons, ²​volume_cubic_yards, ³​plastic_bottles, ⁴​polystyrene

Finally, I will combine the Professor Trash Wheel data with the
Mr. Trash Wheel data to produce a single tidy dataset. I will use a
full_join since observations in each dataset are distinct:

``` r
trash_tidy = full_join(mr_trash, prof_trash)
```

    ## Joining, by = c("dumpster", "month", "year", "date", "weight_tons",
    ## "volume_cubic_yards", "plastic_bottles", "polystyrene", "cigarette_butts",
    ## "glass_bottles", "grocery_bags", "chip_bags", "homes_powered", "class")

``` r
print(trash_tidy)
```

    ## # A tibble: 568 × 15
    ##    dumpster month  year date                weight_tons volume…¹ plast…² polys…³
    ##       <dbl> <chr> <dbl> <dttm>                    <dbl>    <dbl>   <dbl>   <dbl>
    ##  1        1 May    2014 2014-05-16 00:00:00        4.31       18    1450    1820
    ##  2        2 May    2014 2014-05-16 00:00:00        2.74       13    1120    1030
    ##  3        3 May    2014 2014-05-16 00:00:00        3.45       15    2450    3100
    ##  4        4 May    2014 2014-05-17 00:00:00        3.1        15    2380    2730
    ##  5        5 May    2014 2014-05-17 00:00:00        4.06       18     980     870
    ##  6        6 May    2014 2014-05-20 00:00:00        2.71       13    1430    2140
    ##  7        7 May    2014 2014-05-21 00:00:00        1.91        8     910    1090
    ##  8        8 May    2014 2014-05-28 00:00:00        3.7        16    3580    4310
    ##  9        9 June   2014 2014-06-05 00:00:00        2.52       14    2400    2790
    ## 10       10 June   2014 2014-06-11 00:00:00        3.76       18    1340    1730
    ## # … with 558 more rows, 7 more variables: cigarette_butts <dbl>,
    ## #   glass_bottles <dbl>, grocery_bags <dbl>, chip_bags <dbl>,
    ## #   sports_balls <int>, homes_powered <dbl>, class <chr>, and abbreviated
    ## #   variable names ¹​volume_cubic_yards, ²​plastic_bottles, ³​polystyrene

This dataset displays data for dumpsters in Mr. Trash Wheel and
Professor Trash Wheel. The resulting dataset includes 568 observations
and 15 columns, including the new column/variable ‘class’ to distinguish
dumpster type. Key variables include date, weight, volume, trash type
(plastic bottles:sports balls), and homes powered by the trash once
incinerated. According to our data, the total weight of trash collected
by Professor Trash Wheel is 162.54 tons. The total number of sports
balls collected by Mr. Trash wheel in 2020 is 856.

## Problem 3

First, I will clean the data in pols-month.csv. This code will use
`separate()` to break up the variable mon into integer variables year,
month, and day; replace month number with month name; create a president
variable taking values gop and dem, and remove prez_dem and prez_gop;
and remove the day variable.

``` r
pols = read_csv("data/fivethirtyeight_datasets/pols-month.csv") %>%
  janitor::clean_names() %>%
  separate(col = mon, into = c("year", "month", "day"), sep = "-") %>%
  select(-day) %>%
  mutate(
    month = month.name[as.numeric(month)], 
    month = factor(month, levels = month.name),
    year = as.numeric(year),
    prez_dem = recode(prez_dem, `1` = "dem", `0` = "gop", ), 
    prez_gop = recode(prez_gop, `1` = "gop", `0` = "dem", `2` = "unexpected")) %>%
  pivot_longer(
    cols = starts_with("prez"),
    names_to = NULL,
    values_to = "president") %>%
  distinct()
```

    ## Rows: 822 Columns: 9
    ## ── Column specification ────────────────────────────────────────────────────────
    ## Delimiter: ","
    ## dbl  (8): prez_gop, gov_gop, sen_gop, rep_gop, prez_dem, gov_dem, sen_dem, r...
    ## date (1): mon
    ## 
    ## ℹ Use `spec()` to retrieve the full column specification for this data.
    ## ℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.

``` r
print(pols) #RETURNS N= 827 INSTEAD OF N=822 BC OF 5 "2" VALUES. PIVOT LONGER ERROR.
```

    ## # A tibble: 827 × 9
    ##     year month     gov_gop sen_gop rep_gop gov_dem sen_dem rep_dem president
    ##    <dbl> <fct>       <dbl>   <dbl>   <dbl>   <dbl>   <dbl>   <dbl> <chr>    
    ##  1  1947 January        23      51     253      23      45     198 dem      
    ##  2  1947 February       23      51     253      23      45     198 dem      
    ##  3  1947 March          23      51     253      23      45     198 dem      
    ##  4  1947 April          23      51     253      23      45     198 dem      
    ##  5  1947 May            23      51     253      23      45     198 dem      
    ##  6  1947 June           23      51     253      23      45     198 dem      
    ##  7  1947 July           23      51     253      23      45     198 dem      
    ##  8  1947 August         23      51     253      23      45     198 dem      
    ##  9  1947 September      23      51     253      23      45     198 dem      
    ## 10  1947 October        23      51     253      23      45     198 dem      
    ## # … with 817 more rows

Second, I will clean the data in snp.csv using a similar process to that
above. For consistency across datasets, I will arrange according to year
and month, and organize so that year and month are the leading columns.

``` r
snp = read_csv("data/fivethirtyeight_datasets/snp.csv") %>%
  janitor::clean_names() %>%
  separate(col = date, into = c("month", "day", "year"), sep = "/") %>%
  mutate(
    month = month.name[as.numeric(month)],
    month = factor(month, levels = month.name), 
    year = ifelse(as.numeric(year) > 22, as.numeric(year) + 1900, as.numeric(year) + 2000)) %>%
  arrange(year, month) %>%
  select(year, month, close)
```

    ## Rows: 787 Columns: 2
    ## ── Column specification ────────────────────────────────────────────────────────
    ## Delimiter: ","
    ## chr (1): date
    ## dbl (1): close
    ## 
    ## ℹ Use `spec()` to retrieve the full column specification for this data.
    ## ℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.

``` r
print(snp)
```

    ## # A tibble: 787 × 3
    ##     year month     close
    ##    <dbl> <fct>     <dbl>
    ##  1  1950 January    17.0
    ##  2  1950 February   17.2
    ##  3  1950 March      17.3
    ##  4  1950 April      18.0
    ##  5  1950 May        18.8
    ##  6  1950 June       17.7
    ##  7  1950 July       17.8
    ##  8  1950 August     18.4
    ##  9  1950 September  19.5
    ## 10  1950 October    19.5
    ## # … with 777 more rows

Third, I will tidy the unemployment data so that it can be merged with
the previous datasets. This process will involve switching from “wide”
to “long” format; ensuring that key variables have the same name; and
ensuring that key variables take the same values.

``` r
unemployment_tidy = read_csv("data/fivethirtyeight_datasets/unemployment.csv") %>%
  janitor::clean_names() %>%
  rename(
    January = jan,
    February = feb,
    March = mar,
    April = apr,
    May = may,
    June = jun,
    July = jul,
    August = aug,
    September = sep,
    October = oct,
    November = nov,
    December = dec) %>%
  pivot_longer(
    January:December,
    names_to = "month", 
    values_to = "unemployment_percentage") %>%
  mutate(month = factor(month, levels = month.name))
```

    ## Rows: 68 Columns: 13
    ## ── Column specification ────────────────────────────────────────────────────────
    ## Delimiter: ","
    ## dbl (13): Year, Jan, Feb, Mar, Apr, May, Jun, Jul, Aug, Sep, Oct, Nov, Dec
    ## 
    ## ℹ Use `spec()` to retrieve the full column specification for this data.
    ## ℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.

``` r
print(unemployment_tidy)
```

    ## # A tibble: 816 × 3
    ##     year month     unemployment_percentage
    ##    <dbl> <fct>                       <dbl>
    ##  1  1948 January                       3.4
    ##  2  1948 February                      3.8
    ##  3  1948 March                         4  
    ##  4  1948 April                         3.9
    ##  5  1948 May                           3.5
    ##  6  1948 June                          3.6
    ##  7  1948 July                          3.6
    ##  8  1948 August                        3.9
    ##  9  1948 September                     3.8
    ## 10  1948 October                       3.7
    ## # … with 806 more rows

Join the datasets by merging snp into pols, and merging unemployment
into the result.

``` r
pols_snp_merge = left_join(pols, snp)
```

    ## Joining, by = c("year", "month")

``` r
print(pols_snp_merge)
```

    ## # A tibble: 827 × 10
    ##     year month     gov_gop sen_gop rep_gop gov_dem sen_dem rep_dem presi…¹ close
    ##    <dbl> <fct>       <dbl>   <dbl>   <dbl>   <dbl>   <dbl>   <dbl> <chr>   <dbl>
    ##  1  1947 January        23      51     253      23      45     198 dem        NA
    ##  2  1947 February       23      51     253      23      45     198 dem        NA
    ##  3  1947 March          23      51     253      23      45     198 dem        NA
    ##  4  1947 April          23      51     253      23      45     198 dem        NA
    ##  5  1947 May            23      51     253      23      45     198 dem        NA
    ##  6  1947 June           23      51     253      23      45     198 dem        NA
    ##  7  1947 July           23      51     253      23      45     198 dem        NA
    ##  8  1947 August         23      51     253      23      45     198 dem        NA
    ##  9  1947 September      23      51     253      23      45     198 dem        NA
    ## 10  1947 October        23      51     253      23      45     198 dem        NA
    ## # … with 817 more rows, and abbreviated variable name ¹​president

``` r
final_merge = left_join(pols_snp_merge, unemployment_tidy)
```

    ## Joining, by = c("year", "month")

``` r
print(final_merge)
```

    ## # A tibble: 827 × 11
    ##     year month     gov_gop sen_gop rep_gop gov_dem sen_dem rep_dem presi…¹ close
    ##    <dbl> <fct>       <dbl>   <dbl>   <dbl>   <dbl>   <dbl>   <dbl> <chr>   <dbl>
    ##  1  1947 January        23      51     253      23      45     198 dem        NA
    ##  2  1947 February       23      51     253      23      45     198 dem        NA
    ##  3  1947 March          23      51     253      23      45     198 dem        NA
    ##  4  1947 April          23      51     253      23      45     198 dem        NA
    ##  5  1947 May            23      51     253      23      45     198 dem        NA
    ##  6  1947 June           23      51     253      23      45     198 dem        NA
    ##  7  1947 July           23      51     253      23      45     198 dem        NA
    ##  8  1947 August         23      51     253      23      45     198 dem        NA
    ##  9  1947 September      23      51     253      23      45     198 dem        NA
    ## 10  1947 October        23      51     253      23      45     198 dem        NA
    ## # … with 817 more rows, 1 more variable: unemployment_percentage <dbl>, and
    ## #   abbreviated variable name ¹​president

**Write a short paragraph about these datasets. Explain briefly what
each dataset contained, and describe the resulting dataset (e.g. give
the dimension, range of years, and names of key variables).**

This homework includes three FiveThirtyEight datasets: pols-month, snp,
and unemployment. The “pols-month” data, tidied and renamed here as
“pols,” contains 827 observations of 9 variables related to the number
of national politicians who are democratic or republican at any given
time. The “snp” data includes 787 observations of 3 variables related to
Standard & Poor’s stock market index (S&P). The variable close
represents the closing values of the S&P stock index on the associated
date. The “unemployment” data, tidied and renamed here as
“unemployment_tidy,” includes 816 observations of 3 variables,
displaying the percentage of unemployment for each month in each
associated year. The resulting data set “final_merge” merges data from
all three datasets using two `left_joins()`. This final dataset contains
827 observations of 11 variables. Key variables include year, month,
president, close, and unemployment_percentage.
